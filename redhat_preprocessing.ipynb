{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the activity training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "act_train_location = os.path.realpath('')+'/act_train.csv'\n",
    "df_act_train = pd.read_csv(act_train_location)\n",
    "df_act_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the activity test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "act_test_location = os.path.realpath('')+'/act_test.csv'\n",
    "df_act_test = pd.read_csv(act_test_location)\n",
    "df_act_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the people dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "people_location = os.path.realpath('')+'/people.csv'\n",
    "df_people = pd.read_csv(people_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing column names to differentiate activity characteristics from people characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newcolnames = []\n",
    "for colname in df_act_train.columns:\n",
    "    if 'char' in colname and 'a_' not in colname:\n",
    "        newcolnames.append('a_'+colname)\n",
    "    elif 'date' in colname:\n",
    "        newcolnames.append('a_'+colname)\n",
    "    else:\n",
    "        newcolnames.append(colname)\n",
    "df_act_train.columns = newcolnames\n",
    "newcolnames = []\n",
    "for colname in df_people.columns:\n",
    "    if 'char' in colname and 'p_' not in colname:\n",
    "        newcolnames.append('p_'+colname)\n",
    "    elif 'date' in colname:\n",
    "        newcolnames.append('p_'+colname)        \n",
    "    else:\n",
    "        newcolnames.append(colname)\n",
    "df_people.columns = newcolnames\n",
    "\n",
    "newcolnames = []\n",
    "for colname in df_act_test.columns:\n",
    "    if 'char' in colname and 'a_' not in colname:\n",
    "        newcolnames.append('a_'+colname)\n",
    "    elif 'date' in colname:\n",
    "        newcolnames.append('a_'+colname)\n",
    "    else:\n",
    "        newcolnames.append(colname)\n",
    "df_act_test.columns = newcolnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting index to people id before performing join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_act_train = df_act_train.set_index('people_id')\n",
    "df_people = df_people.set_index('people_id')\n",
    "df_act_test = df_act_test.set_index('people_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the training and test datasets by joining them with people information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_act_train.join(df_people)\n",
    "df_test = df_act_test.join(df_people)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill NaN with 'type -1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test.fillna(value = 'type -1',inplace=True)\n",
    "df_train.fillna(value = 'type -1',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resetting index to activity id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index()\n",
    "df_train.set_index('activity_id',inplace=True)\n",
    "\n",
    "df_test = df_test.reset_index()\n",
    "df_test.set_index('activity_id',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate training and test datasets before using label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_comp = pd.concat([df_train,df_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = np.empty(list(X.shape),dtype=int)\n",
    "        if self.columns is not None:\n",
    "            for i,col in enumerate(self.columns):\n",
    "                output[:,i] = LabelEncoder().fit_transform(X[col])\n",
    "        else:\n",
    "            for i,col in enumerate(X.columns):\n",
    "                output[:,i] = LabelEncoder().fit_transform(X[col])\n",
    "        return output\n",
    "    \n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chk = MultiColumnLabelEncoder().fit_transform(df_comp.drop(['a_date','outcome','p_date','p_char_38'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chk = np.append(chk,df_comp.p_char_38.reshape(-1,1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving label encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('data.h5', 'w') as hf:\n",
    "    hf.create_dataset('dataset_1', data=chk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
